{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP2: Classification non supervisée (clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KMeans sur un dataset synthétique\n",
    "Créez un dataset synthétique à partir de [make_blobs](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_blobs.html) 300 échantillons, 4 centres, un écart type de 0.6 et une graine du générateur aléatoire (*random_state*) à 0.\n",
    "Affichez le à l'aide de la fonction [scatter de matplotlib](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.scatter.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est relativement facile de repérer les quatre clusters. L'algorithme [k-means de scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans) va le faire automatiquement. Utilisez-le en précisant de chercher 4 clusters dans les paramètres du KMeans.\n",
    "Stockez dans une variable le resultat de la fonction [*predict*](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans.predict) qui va renvoyer l'indice du cluster à laquelle appartient chaque échantillon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisons les résultats en traçant les données en fonction de leur numéro de cluster toujours avec *scatter* (précisez 'viridis' en cmap). Nous allons également tracer en noir les centres des clusters tels que déterminés par l'estimateur k-means (attribut *cluster_centers_* de l'instance de kmeans sur laquelle vous travaillez)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KMeans sur le jeu de données Iris\n",
    "Utilisation d'un jeu de données \"réel\", [Iris](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html#sklearn.datasets.load_iris). Chargez le jeu de données dans une variable *iris* et affichez les données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#affichage des données, vous permet de mieux comprendre le jeu de données (optionnel)\n",
    "print(iris.feature_names)\n",
    "print(iris.target)\n",
    "print(iris.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stocker les données et les cibles (*target*) dans des DataFrames panda (en précisant les noms de colonnes de données)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#Stocker les données en tant que DataFrame Pandas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utiliser la fonction KMeans de sklearn sur ce jeu de données avec 3 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#Cluster K-means\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichez le résultat du clustering en couleur à l'aide de *[scatterplot](https://seaborn.pydata.org/generated/seaborn.scatterplot.html)* de seaborn, rouge pour le cluster 0, vert pour le 1 et bleu pour le 2. Utilisez dans un premier temps la longeur des pétales en X et la largueur des pétales en Y. Changez la forme des points en fonction du type d'iris *iris.target* et *iris.target_names*. Est-ce que tous les iris sont dans le bon groupe ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A l'aide de *[subplot](https://matplotlib.org/stable/gallery/subplots_axes_and_figures/subplots_demo.html)* affichez les différentes combinaisons possibles de choix de 2 axes parmis les 4 possibles pour choisir le meilleur couple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qualité du kMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons affiché les éléments mal classifiés, nous pouvons maintenant vérifier la précision de notre classification non supervisée avec *[accuracy_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichons la matrice de confusion *[confusion_matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)* qui va nous permettre d'évaluer la précision de la classification par classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Codage de son propre kmeans\n",
    "Coder votre propre kmeans et comparez les résultats de votre code avec la classification précédente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#codage du k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# test sur les données synthétiques\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# test sur iris\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtention du meilleur nombre de clusters\n",
    "Déterminer le nombre optimal de clusters dans un ensemble de données est une question fondamentale dans le clustering par partitionnement, tel que le clustering k-means, qui nécessite que l'utilisateur spécifie le nombre de clusters k à générer. Le nombre optimal de clusters dépend de la méthode utilisée pour mesurer les similarités et des paramètres utilisés pour le partitionnement.\n",
    "les méthodes directes consistent à optimiser un critère, tel que les sommes de carrés à l'intérieur d'un cluster ou la silhouette moyenne. Les méthodes correspondantes sont appelées respectivement méthodes du coude *elbow* et de la silhouette moyenne.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Méthode *elbow*\n",
    "\n",
    "Rappelons que l'idée de base des méthodes de partitionnement, telles que le clustering k-means, est de définir des clusters de telle sorte que l'inertie totale soit minimisée. L'inertie est calculée comme la somme des carrés des distances des échantillons à leur centre de cluster le plus proche.\n",
    "\n",
    "La méthode Elbow considère l'inertie comme une fonction du nombre de clusters : Il faut choisir un nombre de clusters tel que l'ajout d'un autre cluster n'améliore pas beaucoup plus l'inertie total.\n",
    "\n",
    "Le nombre optimal de clusters peut être défini comme suit :\n",
    "\n",
    "- Effectuer le kmeans pour différentes valeurs de k. Par exemple, en faisant varier k de 1 à 10 clusters.\n",
    "- Pour chaque k, calculer l'inertie totale (donnée comme un [attribut](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html) de l'instance de kmeans manipulée).\n",
    "- Tracez la courbe de l'inertie en fonction du nombre de clusters k.\n",
    "- L'emplacement d'un point d'inflexion dans le tracé est généralement considéré comme un indicateur du nombre approprié de clusters.\n",
    "\n",
    "Tracez cette courbe pour les iris (K de 1 à 10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Méthode de la [silhouette moyenne](https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html)\n",
    "\n",
    "Pour chaque point, son coefficient de silhouette est la différence entre la distance moyenne avec les points du même groupe que lui (cohésion) et la distance moyenne avec les points des autres groupes voisins (séparation). Si cette différence est négative, le point est en moyenne plus proche du groupe voisin que du sien : il est donc mal classé. À l'inverse, si cette différence est positive, le point est en moyenne plus proche de son groupe que du groupe voisin : il est donc bien classé.\n",
    "\n",
    "Le coefficient de silhouette proprement dit est la moyenne du coefficient de silhouette pour tous les points.\n",
    "La méthode de la silhouette moyenne calcule la silhouette moyenne des observations pour différentes valeurs de k. Le nombre optimal de clusters k est celui qui maximise la silhouette moyenne sur une gamme de valeurs possibles pour k.\n",
    "\n",
    "L'algorithme est similaire à la méthode *elbow* et peut être calculé comme suit :\n",
    "\n",
    "- Effectuer le kmeans pour différentes valeurs de k. Par exemple, en faisant varier k de 2 à 10 clusters.\n",
    "- Pour chaque k, calculer la silhouette moyenne des observations (avg.sil).\n",
    "- Tracez la courbe de avg.sil en fonction du nombre de clusters k.\n",
    "- L'emplacement du maximum est considéré comme le nombre approprié de clusters.\n",
    "\n",
    "De même que précédement, appliquez cette méthode sur les iris."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Ascendante Hiérarchique (CAH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chargez et affichez le jeu de données `zoo`. Que contient ce dataset ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combien y a-t-il d'espèces différentes ? Affichez leur nom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extrayez les features dans une matrice `numpy`, puis normalisez les données à l'aide de [StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CAH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre objectif est de créer une classification des espèces en utilisant seulement les caractéristiques de chaque animal (i.e. toutes les colonnes sauf `type` et `name`). Ces classifications se présentent souvent sous la forme d'arbres, d'où le choix de la CAH. On pourra ensuite comparer notre classification à celle donnée dans le dataset.\n",
    "\n",
    "Nous utiliserons la classe [AgglomerativeClustering](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html#sklearn.cluster.AgglomerativeClustering) de scikit-learn. Dans un premier temps, utilisez `distance_threshold=0` pour calculer tout l'arbre. On choisira ensuite le nombre de clusters qui nous intéresse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Visualisation du clustering avec un dendrogramme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilisez la fonction `plot_dendrogram` pour représenter votre CAH. Pour les labels, utilisez ceux présents dans le dataset `zoo` pour comparer le votre classification à la classification scientifique des espèces. Essayez plusieurs valeurs de `n_clusters` et comparer les classifications. Vous pourrez utiliser la fonction `savefig` de matplotlib pour sauvegarder le dendrogramme et zoomer dans l'image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram\n",
    "\n",
    "\n",
    "def plot_dendrogram(model, labels=None, **kwargs):\n",
    "    # Create linkage matrix and then plot the dendrogram\n",
    "    if labels is not None:\n",
    "        assert len(labels) == len(model.children_) + 1\n",
    "    # create the counts of samples under each node\n",
    "    counts = np.zeros(model.children_.shape[0])\n",
    "    n_samples = len(model.labels_)\n",
    "    for i, merge in enumerate(model.children_):\n",
    "        current_count = 0\n",
    "        for child_idx in merge:\n",
    "            if child_idx < n_samples:\n",
    "                current_count += 1  # leaf node\n",
    "            else:\n",
    "                current_count += counts[child_idx - n_samples]\n",
    "        counts[i] = current_count\n",
    "\n",
    "    linkage_matrix = np.column_stack(\n",
    "        [model.children_, model.distances_, counts]\n",
    "    ).astype(float)\n",
    "\n",
    "    # Plot the corresponding dendrogram\n",
    "    dendrogram(linkage_matrix, labels=labels, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Choix du nombre de clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichez un barplot des gains d'inertie (les hauteurs dans le dendrogramme). Ils se trouvent dans l'attribut [distances_](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html) d'`AgglomerativeClustering`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de ce graphique, déterminez un nombre raisonnable de clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculez les métriques [Silhouette](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html) et [Davies-Bouldin](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.davies_bouldin_score.html) pour plusieurs valeurs de `n_clusters`. \n",
    "\n",
    "Plus d'information sur ces métriques dans le Guide de l'Utiliateur de scikit-learn:\n",
    "- silhouette: https://scikit-learn.org/stable/modules/clustering.html#silhouette-coefficient\n",
    "- davies-bouldin: https://scikit-learn.org/stable/modules/clustering.html#davies-bouldin-index\n",
    "\n",
    "Choisissez un nombre de clusters à l'aide de ces métriques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisez à nouveau le dendrogramme avec le(s) nombre(s) de clusters que vous avez choisi et comparez à la classification scientifique des espèces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Comparaison de linkages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refaite un clustering hiérarchique avec `linkage=single`. Affichez le dendrogramme complet et comparez avec le dendrogramme obtenu précédemment avec le linkage par défaut (`ward`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La cellule suivante crée plusieurs jeux de données 2D. Effectuez un clustering de chacun de ces jeux de données pour les 4 linkage disponibles (voir la doc d'`AgglomerativeClustering`), avec le bon nombre de clusters (celui utilisé pour générer le jeu de données) pour se placer dans un cas favorable. N'oubliez pas de standardiser les données ! Affichez les clusterings sur une mosaïque ainsi que la \"vraie\" classification en colorant les points et comparez les résultats. Quelle remarque pouvez-vous faire sur la taille des clusters pour le linkage \"single\" ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import cluster, datasets\n",
    "\n",
    "# Génération de plusieurs datasets\n",
    "np.random.seed(0)\n",
    "n_samples = 1500\n",
    "\n",
    "noisy_circles = datasets.make_circles(n_samples=n_samples, factor=0.5, noise=0.05)\n",
    "noisy_moons = datasets.make_moons(n_samples=n_samples, noise=0.05)\n",
    "blobs = datasets.make_blobs(n_samples=n_samples, random_state=8)\n",
    "# pas de \"clusters\" pour no_structure, on les met tous dans la même catégorie pour la visualisation\n",
    "no_structure = np.random.rand(n_samples, 2), np.zeros(n_samples, dtype=np.uint8)\n",
    "\n",
    "random_state = 170\n",
    "X, y = datasets.make_blobs(n_samples=n_samples, random_state=random_state)\n",
    "transformation = [[0.6, -0.6], [-0.4, 0.8]]\n",
    "X_aniso = np.dot(X, transformation)\n",
    "aniso = (X_aniso, y)\n",
    "\n",
    "varied = datasets.make_blobs(\n",
    "    n_samples=n_samples, cluster_std=[1.0, 2.5, 0.5], random_state=random_state\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Tous les datasets: liste de tuples (dataset, n_clusters). \n",
    "# Un dataset est un couple (X, labels) avec X: matrice de features, y: \"vrai\" labels (sauf pour no_structure)\n",
    "data = [\n",
    "    (noisy_circles, 2),\n",
    "    (noisy_moons, 2),\n",
    "    (varied, 3),\n",
    "    (aniso, 3),\n",
    "    (blobs, 3),\n",
    "    (no_structure, 3),  # pas de ground truth ici, mais on va chercher 3 clusters\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single linkage a tendance à créer de très gros clusters et d'autres quasi vides (rich get richer), ce qu'on remarque aussi sur `zoo`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparaison de clusterings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il existe des métriques pour comparer des clusterings entre eux. Nous allons utiliser l'ARI https://en.wikipedia.org/wiki/Rand_index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import adjusted_rand_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme nous disposons des labels pour le jeu de donnée `zoo`, affichez l'ARI entre un clustering CAH et la ground truth, en faisant varier le nombre de clusters. Faites de même avec un k-means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparez maintenant les deux méthodes de clustering entre elles. Les clusterings obtenus sont-ils similaires ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les scores sont assez élevés, les deux méthodes ont l'air de fournir des clusterings assez similaires sur ce jeu de données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini batch kmeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implémentez une fonction mini-batch kmeans. L'algorithme est disponible dans cet article (*Algorithm 1*) https://www.eecs.tufts.edu/~dsculley/papers/fastkmeans.pdf.\n",
    "\n",
    "Comparer les clustering obtenus par vos deux fonctions kmeans et mini batch kmeans, pour une même initialisation. On pourra appliquer ces deux fonctions sur un échantillon de grande taille de données simulées. On pourra lancer plusieurs fois l’algorithme et dresser le boxplot de l’ARI entre les deux clusterings. Comparez aussi les temps d'exécution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
